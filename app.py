import os
import torch
from flask import Flask, request, jsonify, render_template, send_from_directory
from flask_cors import CORS
from werkzeug.utils import secure_filename
from PIL import Image
import io
import base64
from config import *
from transformers import AutoModel, AutoTokenizer

app = Flask(__name__)
CORS(app)
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['MAX_CONTENT_LENGTH'] = MAX_FILE_SIZE

# Global model and tokenizer
model = None
tokenizer = None

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def init_model():
    """Initialize the DeepSeek-OCR model"""
    global model, tokenizer
    try:
        # Hi·ªÉn th·ªã th√¥ng tin c·∫•u h√¨nh
        print("=" * 60)
        print("C·∫•u h√¨nh h·ªá th·ªëng:")
        print(f"  - Device: {DEVICE}")
        print(f"  - Dtype: {DTYPE}")
        print(f"  - Image size: {IMAGE_SIZE}x{IMAGE_SIZE}")
        print(f"  - Base size: {BASE_SIZE}")
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
            print(f"  - GPU: {gpu_name} ({gpu_memory:.1f}GB VRAM)")
        else:
            print("  - GPU: Kh√¥ng c√≥ (s·ª≠ d·ª•ng CPU)")
        print("=" * 60)
        
        print("\nƒêang t·∫£i tokenizer...")
        tokenizer = AutoTokenizer.from_pretrained(
            MODEL_NAME, 
            trust_remote_code=True
        )
        
        print("ƒêang t·∫£i model (c√≥ th·ªÉ m·∫•t v√†i ph√∫t l·∫ßn ƒë·∫ßu)...")
        print("L∆∞u √Ω: Model s·∫Ω ƒë∆∞·ª£c t·∫£i t·ª´ Hugging Face (~20-30GB)")
        
        # Ki·ªÉm tra v√† c√†i flash-attn n·∫øu c·∫ßn (ƒë·ªÉ c√≥ LlamaFlashAttention2)
        try:
            import flash_attn
            print("‚úÖ flash-attn ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t")
        except ImportError:
            print("‚ö†Ô∏è  flash-attn ch∆∞a ƒë∆∞·ª£c c√†i. Model code c√≥ th·ªÉ c·∫ßn n√≥.")
            print("   ƒêang th·ª≠ t·∫£i model m√† kh√¥ng d√πng flash attention...")
        
        # Th·ª≠ load model - model code s·∫Ω t·ª± x·ª≠ l√Ω flash attention
        try:
            # Kh√¥ng ch·ªâ ƒë·ªãnh _attn_implementation ƒë·ªÉ model t·ª± quy·∫øt ƒë·ªãnh
            model = AutoModel.from_pretrained(
                MODEL_NAME,
                trust_remote_code=True,
                use_safetensors=True
            )
        except Exception as e:
            error_msg = str(e)
            if "LlamaFlashAttention2" in error_msg or "flash" in error_msg.lower():
                print("\n‚ö†Ô∏è  L·ªói li√™n quan ƒë·∫øn flash attention.")
                print("üí° Gi·∫£i ph√°p: C√†i flash-attn ho·∫∑c c·∫≠p nh·∫≠t transformers")
                print("\nCh·∫°y l·ªánh sau ƒë·ªÉ kh·∫Øc ph·ª•c:")
                print("  pip install flash-attn==2.7.3 --no-build-isolation")
                print("  ho·∫∑c")
                print("  pip install --upgrade transformers>=4.46.0")
                raise Exception(f"Model y√™u c·∫ßu flash-attn ho·∫∑c transformers m·ªõi h∆°n. L·ªói: {error_msg}")
            else:
                raise Exception(f"Kh√¥ng th·ªÉ t·∫£i model: {error_msg}")
        
        # Move to device and set dtype
        dtype_map = {
            'bfloat16': torch.bfloat16,
            'float16': torch.float16,
            'float32': torch.float32
        }
        dtype = dtype_map.get(DTYPE, torch.bfloat16)
        
        model = model.eval()
        if torch.cuda.is_available() and DEVICE == 'cuda':
            print(f"ƒêang chuy·ªÉn model l√™n GPU v·ªõi dtype={DTYPE}...")
            model = model.cuda().to(dtype)
        else:
            print(f"ƒêang chuy·ªÉn model l√™n CPU v·ªõi dtype={DTYPE}...")
            model = model.to(dtype)
        
        print("\n‚úÖ Model ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng!")
        print("=" * 60)
        return True
    except Exception as e:
        print(f"\n‚ùå L·ªói khi t·∫£i model: {str(e)}")
        print("\nG·ª£i √Ω kh·∫Øc ph·ª•c:")
        print("  1. Ki·ªÉm tra k·∫øt n·ªëi internet")
        print("  2. ƒê·∫£m b·∫£o c√≥ ƒë·ªß dung l∆∞·ª£ng ·ªï c·ª©ng (50GB+)")
        print("  3. Th·ª≠ ƒë·ªïi DEVICE='cpu' trong config.py n·∫øu GPU c√≥ v·∫•n ƒë·ªÅ")
        print("  4. Gi·∫£m IMAGE_SIZE trong config.py n·∫øu thi·∫øu RAM/VRAM")
        return False

@app.route('/')
def index():
    """Render the main page"""
    return render_template('index.html')

@app.route('/health')
def health():
    """Health check endpoint"""
    return jsonify({
        'status': 'ok',
        'model_loaded': model is not None,
        'device': DEVICE,
        'cuda_available': torch.cuda.is_available()
    })

@app.route('/api/ocr', methods=['POST'])
def ocr():
    """Process OCR request"""
    try:
        if model is None or tokenizer is None:
            return jsonify({
                'success': False,
                'error': 'Model ch∆∞a ƒë∆∞·ª£c t·∫£i. Vui l√≤ng ƒë·ª£i...'
            }), 503
        
        # Check if file is present
        if 'image' not in request.files:
            return jsonify({
                'success': False,
                'error': 'Kh√¥ng t√¨m th·∫•y file ·∫£nh'
            }), 400
        
        file = request.files['image']
        if file.filename == '':
            return jsonify({
                'success': False,
                'error': 'Ch∆∞a ch·ªçn file'
            }), 400
        
        if not allowed_file(file.filename):
            return jsonify({
                'success': False,
                'error': f'ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£. Ch·ªâ ch·∫•p nh·∫≠n: {", ".join(ALLOWED_EXTENSIONS)}'
            }), 400
        
        # Get prompt from form
        prompt_text = request.form.get('prompt', '<image>\nFree OCR.')
        if not prompt_text.strip():
            prompt_text = '<image>\nFree OCR.'
        
        # Read image
        image_bytes = file.read()
        image = Image.open(io.BytesIO(image_bytes)).convert('RGB')
        
        # Save uploaded file
        filename = secure_filename(file.filename)
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        image.save(filepath)
        
        # Process OCR
        output_path = os.path.join(OUTPUT_FOLDER, f"result_{filename}")
        
        try:
            result = model.infer(
                tokenizer,
                prompt=prompt_text,
                image_file=filepath,
                output_path=output_path,
                base_size=BASE_SIZE,
                image_size=IMAGE_SIZE,
                crop_mode=CROP_MODE,
                save_results=True,
                test_compress=True
            )
        except Exception as e:
            raise Exception(f"L·ªói khi x·ª≠ l√Ω OCR: {str(e)}")
        
        # Read result - try multiple methods
        result_text = ""
        
        # Method 1: Try to read from output file first (most reliable)
        txt_file = f"{output_path}.txt"
        if os.path.exists(txt_file):
            try:
                with open(txt_file, 'r', encoding='utf-8') as f:
                    result_text = f.read().strip()
            except Exception as e:
                print(f"Warning: Kh√¥ng th·ªÉ ƒë·ªçc file {txt_file}: {e}")
        
        # Method 2: If no file, try to get from result object
        if not result_text:
            if isinstance(result, dict):
                result_text = result.get('text', result.get('result', str(result)))
            elif isinstance(result, str):
                result_text = result
            elif hasattr(result, 'text'):
                result_text = result.text
            else:
                result_text = str(result)
        
        # Clean up result text
        if result_text:
            result_text = result_text.strip()
        
        return jsonify({
            'success': True,
            'text': result_text,
            'filename': filename
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'L·ªói x·ª≠ l√Ω: {str(e)}'
        }), 500

@app.route('/api/ocr-base64', methods=['POST'])
def ocr_base64():
    """Process OCR from base64 image"""
    try:
        if model is None or tokenizer is None:
            return jsonify({
                'success': False,
                'error': 'Model ch∆∞a ƒë∆∞·ª£c t·∫£i. Vui l√≤ng ƒë·ª£i...'
            }), 503
        
        data = request.get_json()
        if not data or 'image' not in data:
            return jsonify({
                'success': False,
                'error': 'Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ·∫£nh'
            }), 400
        
        # Decode base64 image
        image_data = data['image']
        if image_data.startswith('data:image'):
            image_data = image_data.split(',')[1]
        
        image_bytes = base64.b64decode(image_data)
        image = Image.open(io.BytesIO(image_bytes)).convert('RGB')
        
        # Get prompt
        prompt_text = data.get('prompt', '<image>\nFree OCR.')
        if not prompt_text.strip():
            prompt_text = '<image>\nFree OCR.'
        
        # Save temporary file
        import uuid
        temp_filename = f"temp_{uuid.uuid4().hex}.png"
        temp_filepath = os.path.join(app.config['UPLOAD_FOLDER'], temp_filename)
        image.save(temp_filepath)
        
        # Process OCR
        output_path = os.path.join(OUTPUT_FOLDER, f"result_{temp_filename}")
        
        try:
            result = model.infer(
                tokenizer,
                prompt=prompt_text,
                image_file=temp_filepath,
                output_path=output_path,
                base_size=BASE_SIZE,
                image_size=IMAGE_SIZE,
                crop_mode=CROP_MODE,
                save_results=True,
                test_compress=True
            )
        except Exception as e:
            raise Exception(f"L·ªói khi x·ª≠ l√Ω OCR: {str(e)}")
        
        # Read result - try multiple methods
        result_text = ""
        
        # Method 1: Try to read from output file first (most reliable)
        txt_file = f"{output_path}.txt"
        if os.path.exists(txt_file):
            try:
                with open(txt_file, 'r', encoding='utf-8') as f:
                    result_text = f.read().strip()
            except Exception as e:
                print(f"Warning: Kh√¥ng th·ªÉ ƒë·ªçc file {txt_file}: {e}")
        
        # Method 2: If no file, try to get from result object
        if not result_text:
            if isinstance(result, dict):
                result_text = result.get('text', result.get('result', str(result)))
            elif isinstance(result, str):
                result_text = result
            elif hasattr(result, 'text'):
                result_text = result.text
            else:
                result_text = str(result)
        
        # Clean up result text
        if result_text:
            result_text = result_text.strip()
        
        # Clean up temp file
        try:
            os.remove(temp_filepath)
        except:
            pass
        
        return jsonify({
            'success': True,
            'text': result_text
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'L·ªói x·ª≠ l√Ω: {str(e)}'
        }), 500

if __name__ == '__main__':
    print("=" * 50)
    print("ƒêang kh·ªüi t·∫°o DeepSeek-OCR Web Application...")
    print("=" * 50)
    
    # Initialize model
    if init_model():
        print(f"\nServer ƒëang ch·∫°y t·∫°i: http://{HOST}:{PORT}")
        print("Nh·∫•n Ctrl+C ƒë·ªÉ d·ª´ng server\n")
        app.run(host=HOST, port=PORT, debug=DEBUG)
    else:
        print("Kh√¥ng th·ªÉ kh·ªüi t·∫°o model. Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u h√¨nh.")

