import os
import torch
import re
from flask import Flask, request, jsonify, render_template, send_from_directory, send_file
from flask_cors import CORS
from werkzeug.utils import secure_filename
from PIL import Image
import io
import base64
from config import *
from transformers import AutoModel, AutoTokenizer

def format_ocr_result(text, output_format='markdown'):
    """Format OCR result - Gi·ªØ nguy√™n output t·ª´ DeepSeek-OCR"""
    if not text:
        return text
    
    # N·∫øu output ƒë√£ l√† markdown s·∫°ch (kh√¥ng c√≥ tags), gi·ªØ nguy√™n 100%
    if output_format == 'markdown' and '<|ref|>' not in text and '<|det|>' not in text:
        # ƒê√£ l√† markdown s·∫°ch t·ª´ model, gi·ªØ nguy√™n ho√†n to√†n
        return text
    
    # N·∫øu c√≥ <|ref|> v√† <|det|> tags (grounding format)
    if '<|ref|>' in text and '<|det|>' in text:
        if output_format == 'markdown':
            # Convert sang markdown ƒë·∫πp
            return format_to_markdown(text)
        elif output_format == 'full':
            # Gi·ªØ nguy√™n format v·ªõi bounding boxes
            return format_with_boxes(text)
        else:
            # Ch·ªâ l·∫•y text, b·ªè tags
            return extract_text_only(text)
    else:
        # Kh√¥ng c√≥ tags, tr·∫£ v·ªÅ nguy√™n b·∫£n (c√≥ th·ªÉ ƒë√£ l√† markdown)
        return text

def format_to_markdown(text):
    """Convert OCR result v·ªõi <|ref|> tags sang markdown - Gi·ªØ layout ƒë·∫πp"""
    lines = text.split('\n')
    markdown_lines = []
    last_tag = None
    last_was_title = False
    
    for i, line in enumerate(lines):
        original_line = line
        line_stripped = line.strip()
        
        # Gi·ªØ empty lines ƒë·ªÉ gi·ªØ layout
        if not line_stripped:
            if last_was_title:
                continue  # B·ªè empty line sau title
            markdown_lines.append('')
            continue
            
        # Parse <|ref|>tag<|/ref|><|det|>[[x1,y1,x2,y2]]<|/det|>
        ref_match = re.search(r'<\|ref\|>(.*?)<\|/ref\|>', line)
        det_match = re.search(r'<\|det\|>\[\[(.*?)\]\]<\|/det\|>', line)
        
        if ref_match:
            tag = ref_match.group(1)
            # L·∫•y text sau tags, gi·ªØ nguy√™n spacing
            text_part = re.sub(r'<\|ref\|>.*?<\|/ref\|>', '', line)
            text_part = re.sub(r'<\|det\|>.*?<\|/det\|>', '', text_part)
            text_part = text_part.strip()
            
            if not text_part:
                continue
            
            # Format theo tag type v·ªõi layout ƒë·∫πp
            if tag in ['sub_title', 'title', 'heading']:
                # Th√™m spacing tr∆∞·ªõc title
                if not last_was_title and markdown_lines and markdown_lines[-1]:
                    markdown_lines.append('')
                markdown_lines.append(f'## {text_part}')
                markdown_lines.append('')  # Empty line sau title
                last_was_title = True
                last_tag = tag
            elif tag == 'text':
                # Text b√¨nh th∆∞·ªùng, gi·ªØ nguy√™n
                markdown_lines.append(text_part)
                last_was_title = False
                last_tag = tag
            elif tag == 'image':
                markdown_lines.append('')
                markdown_lines.append(f'![Image]({text_part})')
                markdown_lines.append('')
                last_was_title = False
            elif tag in ['list_item', 'bullet']:
                markdown_lines.append(f'- {text_part}')
                last_was_title = False
            else:
                # Tag kh√°c, format v·ªõi bold
                markdown_lines.append(f'**{text_part}**')
                last_was_title = False
                last_tag = tag
        else:
            # Kh√¥ng c√≥ tags, gi·ªØ nguy√™n text (c√≥ th·ªÉ l√† markdown ƒë√£ ƒë∆∞·ª£c format)
            clean_line = re.sub(r'<\|.*?\|>', '', line).strip()
            if clean_line:
                # Ki·ªÉm tra xem c√≥ ph·∫£i markdown kh√¥ng
                if clean_line.startswith('#') or clean_line.startswith('-') or clean_line.startswith('*'):
                    markdown_lines.append(clean_line)
                else:
                    markdown_lines.append(clean_line)
                last_was_title = False
    
    # Clean up: lo·∫°i b·ªè nhi·ªÅu empty lines li√™n ti·∫øp
    result = []
    prev_empty = False
    for line in markdown_lines:
        if not line.strip():
            if not prev_empty:
                result.append('')
            prev_empty = True
        else:
            result.append(line)
            prev_empty = False
    
    return '\n'.join(result)

def format_with_boxes(text):
    """Format v·ªõi bounding boxes info"""
    lines = text.split('\n')
    formatted_lines = []
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # Parse tags
        ref_match = re.search(r'<\|ref\|>(.*?)<\|/ref\|>', line)
        det_match = re.search(r'<\|det\|>\[\[(.*?)\]\]<\|/det\|>', line)
        
        if ref_match and det_match:
            tag = ref_match.group(1)
            bbox = det_match.group(1)
            text_part = re.sub(r'<\|ref\|>.*?<\|/ref\|>', '', line)
            text_part = re.sub(r'<\|det\|>.*?<\|/det\|>', '', text_part).strip()
            
            formatted_lines.append(f'[{tag}] {text_part} | BBox: {bbox}')
        else:
            clean_line = re.sub(r'<\|.*?\|>', '', line).strip()
            if clean_line:
                formatted_lines.append(clean_line)
    
    return '\n'.join(formatted_lines)

def extract_text_only(text):
    """Ch·ªâ l·∫•y text, b·ªè t·∫•t c·∫£ tags"""
    # Remove all tags
    clean_text = re.sub(r'<\|.*?\|>', '', text)
    # Remove bounding boxes format
    clean_text = re.sub(r'\[\[.*?\]\]', '', clean_text)
    # Clean up multiple spaces
    clean_text = re.sub(r'\s+', ' ', clean_text)
    return clean_text.strip()

# Patch ƒë·ªÉ fix l·ªói DynamicCache.seen_tokens (transformers >= 4.41)
def patch_dynamic_cache():
    """Patch DynamicCache ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi transformers m·ªõi"""
    try:
        from transformers.cache_utils import DynamicCache
        import transformers
        
        # Ki·ªÉm tra version transformers
        version_parts = transformers.__version__.split('.')
        major, minor = int(version_parts[0]), int(version_parts[1])
        
        # N·∫øu transformers >= 4.41, c·∫ßn patch
        if major > 4 or (major == 4 and minor >= 41):
            # Th√™m thu·ªôc t√≠nh seen_tokens n·∫øu ch∆∞a c√≥
            if not hasattr(DynamicCache, 'seen_tokens'):
                def _get_seen_tokens(self):
                    """Get seen_tokens t·ª´ cache_position"""
                    try:
                        if hasattr(self, 'cache_position') and len(self.cache_position) > 0:
                            return len(self.cache_position)
                        elif hasattr(self, 'key_cache') and len(self.key_cache) > 0:
                            # Fallback: t√≠nh t·ª´ key_cache shape
                            return self.key_cache[0].shape[2] if len(self.key_cache) > 0 else 0
                    except:
                        pass
                    return 0
                
                DynamicCache.seen_tokens = property(_get_seen_tokens)
                
                # Th√™m method get_max_length n·∫øu ch∆∞a c√≥
                if not hasattr(DynamicCache, 'get_max_length'):
                    def _get_max_length(self):
                        """Get max length t·ª´ cache"""
                        try:
                            if hasattr(self, 'get_max_cache_shape'):
                                shape = self.get_max_cache_shape()
                                if shape and len(shape) > 1:
                                    return shape[1]
                        except:
                            pass
                        return None
                    DynamicCache.get_max_length = _get_max_length
                
                print("‚úÖ ƒê√£ patch DynamicCache ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi transformers m·ªõi")
    except Exception as e:
        print(f"‚ö†Ô∏è  Kh√¥ng th·ªÉ patch DynamicCache: {e}")

# Ch·∫°y patch ngay khi import
patch_dynamic_cache()

app = Flask(__name__)
CORS(app)
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['MAX_CONTENT_LENGTH'] = MAX_FILE_SIZE

# Global model and tokenizer
model = None
tokenizer = None

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def init_model():
    """Initialize the DeepSeek-OCR model"""
    global model, tokenizer
    try:
        # Hi·ªÉn th·ªã th√¥ng tin c·∫•u h√¨nh
        print("=" * 60)
        print("C·∫•u h√¨nh h·ªá th·ªëng:")
        print(f"  - Device: {DEVICE}")
        print(f"  - Dtype: {DTYPE}")
        print(f"  - Image size: {IMAGE_SIZE}x{IMAGE_SIZE}")
        print(f"  - Base size: {BASE_SIZE}")
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
            print(f"  - GPU: {gpu_name} ({gpu_memory:.1f}GB VRAM)")
        else:
            print("  - GPU: Kh√¥ng c√≥ (s·ª≠ d·ª•ng CPU)")
        print("=" * 60)
        
        print("\nƒêang t·∫£i tokenizer...")
        tokenizer = AutoTokenizer.from_pretrained(
            MODEL_NAME, 
            trust_remote_code=True
        )
        
        print("ƒêang t·∫£i model (c√≥ th·ªÉ m·∫•t v√†i ph√∫t l·∫ßn ƒë·∫ßu)...")
        print("L∆∞u √Ω: Model s·∫Ω ƒë∆∞·ª£c t·∫£i t·ª´ Hugging Face (~20-30GB)")
        
        # Ki·ªÉm tra v√† c√†i flash-attn n·∫øu c·∫ßn (ƒë·ªÉ c√≥ LlamaFlashAttention2)
        has_flash_attn = False
        try:
            import flash_attn
            has_flash_attn = True
            print("‚úÖ flash-attn ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t")
        except ImportError:
            print("‚ö†Ô∏è  flash-attn ch∆∞a ƒë∆∞·ª£c c√†i.")
            print("   ƒêang th·ª≠ t·∫£i model v·ªõi transformers m·∫∑c ƒë·ªãnh...")
        
        # Patch ƒë·ªÉ bypass flash attention n·∫øu c·∫ßn
        if not has_flash_attn:
            try:
                # Th·ª≠ import t·ª´ transformers tr∆∞·ªõc
                from transformers.models.llama import modeling_llama
                if not hasattr(modeling_llama, 'LlamaFlashAttention2'):
                    print("‚ö†Ô∏è  LlamaFlashAttention2 kh√¥ng c√≥ trong transformers.")
                    print("   ƒêang t·∫°o workaround...")
                    # T·∫°o class gi·∫£ ƒë·ªÉ model code kh√¥ng b·ªã l·ªói import
                    class FakeLlamaFlashAttention2:
                        def __init__(self, *args, **kwargs):
                            pass
                    modeling_llama.LlamaFlashAttention2 = FakeLlamaFlashAttention2
                    print("‚úÖ ƒê√£ t·∫°o workaround cho flash attention")
            except Exception as e:
                print(f"‚ö†Ô∏è  Kh√¥ng th·ªÉ patch: {e}")
        
        # Th·ª≠ load model
        try:
            # Kh√¥ng ch·ªâ ƒë·ªãnh _attn_implementation ƒë·ªÉ model t·ª± quy·∫øt ƒë·ªãnh
            model = AutoModel.from_pretrained(
                MODEL_NAME,
                trust_remote_code=True,
                use_safetensors=True
            )
        except Exception as e:
            error_msg = str(e)
            if "LlamaFlashAttention2" in error_msg or "flash" in error_msg.lower():
                print("\n" + "="*60)
                print("‚ö†Ô∏è  L·ªói li√™n quan ƒë·∫øn flash attention.")
                print("="*60)
                print("\nüí° Gi·∫£i ph√°p:")
                print("\n1. C√†i wheel v√† flash-attn:")
                print("   pip install wheel")
                print("   pip install flash-attn==2.7.3 --no-build-isolation")
                print("\n2. Ho·∫∑c c·∫≠p nh·∫≠t transformers:")
                print("   pip install --upgrade transformers>=4.51.0 accelerate")
                print("\n3. Ho·∫∑c c√†i t·ª´ pre-built wheel:")
                print("   pip install flash-attn --no-build-isolation")
                print("="*60)
                raise Exception(f"Model y√™u c·∫ßu flash-attn ho·∫∑c transformers m·ªõi h∆°n. L·ªói: {error_msg}")
            else:
                raise Exception(f"Kh√¥ng th·ªÉ t·∫£i model: {error_msg}")
        
        # Move to device and set dtype
        dtype_map = {
            'bfloat16': torch.bfloat16,
            'float16': torch.float16,
            'float32': torch.float32
        }
        dtype = dtype_map.get(DTYPE, torch.bfloat16)
        
        model = model.eval()
        if torch.cuda.is_available() and DEVICE == 'cuda':
            print(f"ƒêang chuy·ªÉn model l√™n GPU v·ªõi dtype={DTYPE}...")
            print("‚ö†Ô∏è  Qu√° tr√¨nh n√†y c√≥ th·ªÉ m·∫•t 5-10 ph√∫t, vui l√≤ng ƒë·ª£i...")
            print("üí° ƒêang t·∫£i ~6.7GB weights l√™n GPU...")
            
            # Ki·ªÉm tra VRAM tr∆∞·ªõc khi t·∫£i
            torch.cuda.empty_cache()
            free_memory = torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated(0)
            free_memory_gb = free_memory / (1024**3)
            print(f"üìä VRAM c√≤n tr·ªëng: {free_memory_gb:.1f}GB")
            
            if free_memory_gb < 8:
                print("‚ö†Ô∏è  VRAM h∆°i √≠t, c√≥ th·ªÉ m·∫•t nhi·ªÅu th·ªùi gian h∆°n...")
            
            # T·∫£i model l√™n GPU
            try:
                model = model.cuda()
                print("‚úÖ Model ƒë√£ ƒë∆∞·ª£c chuy·ªÉn l√™n GPU")
                print("üîÑ ƒêang chuy·ªÉn ƒë·ªïi dtype...")
                model = model.to(dtype)
                print("‚úÖ Dtype ƒë√£ ƒë∆∞·ª£c chuy·ªÉn ƒë·ªïi")
            except RuntimeError as e:
                if "out of memory" in str(e).lower():
                    print("‚ùå L·ªói: H·∫øt VRAM!")
                    print("üí° Gi·∫£i ph√°p: Gi·∫£m IMAGE_SIZE trong config.py ho·∫∑c d√πng CPU")
                    raise
                else:
                    raise
        else:
            print(f"ƒêang chuy·ªÉn model l√™n CPU v·ªõi dtype={DTYPE}...")
            print("‚ö†Ô∏è  Ch·∫°y tr√™n CPU s·∫Ω r·∫•t ch·∫≠m (30-60s/·∫£nh)...")
            model = model.to(dtype)
        
        # Ki·ªÉm tra model ƒë√£ s·∫µn s√†ng
        torch.cuda.empty_cache()
        if torch.cuda.is_available() and DEVICE == 'cuda':
            allocated = torch.cuda.memory_allocated(0) / (1024**3)
            print(f"üìä VRAM ƒë√£ s·ª≠ d·ª•ng: {allocated:.1f}GB")
        
        print("\n‚úÖ Model ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng!")
        print("=" * 60)
        return True
    except Exception as e:
        print(f"\n‚ùå L·ªói khi t·∫£i model: {str(e)}")
        print("\nG·ª£i √Ω kh·∫Øc ph·ª•c:")
        print("  1. Ki·ªÉm tra k·∫øt n·ªëi internet")
        print("  2. ƒê·∫£m b·∫£o c√≥ ƒë·ªß dung l∆∞·ª£ng ·ªï c·ª©ng (50GB+)")
        print("  3. Th·ª≠ ƒë·ªïi DEVICE='cpu' trong config.py n·∫øu GPU c√≥ v·∫•n ƒë·ªÅ")
        print("  4. Gi·∫£m IMAGE_SIZE trong config.py n·∫øu thi·∫øu RAM/VRAM")
        return False

@app.route('/')
def index():
    """Render the main page"""
    return render_template('index.html')

@app.route('/health')
def health():
    """Health check endpoint"""
    return jsonify({
        'status': 'ok',
        'model_loaded': model is not None,
        'device': DEVICE,
        'cuda_available': torch.cuda.is_available()
    })

@app.route('/outputs/<path:filename>')
def serve_output(filename):
    """Serve files from output directory (for images in markdown)"""
    try:
        return send_from_directory(OUTPUT_FOLDER, filename)
    except Exception as e:
        return jsonify({'error': str(e)}), 404

@app.route('/api/export-docx', methods=['POST'])
def export_docx():
    """Export markdown to DOCX with images"""
    try:
        from docx import Document
        from docx.shared import Inches, Pt
        from docx.enum.text import WD_ALIGN_PARAGRAPH
        import markdown
        from markdown.extensions import fenced_code, tables
        import requests
        from io import BytesIO
        
        data = request.get_json()
        markdown_text = data.get('markdown', '')
        filename = data.get('filename', 'ocr_result.docx')
        
        if not markdown_text:
            return jsonify({'error': 'Kh√¥ng c√≥ n·ªôi dung markdown'}), 400
        
        # T·∫°o document
        doc = Document()
        
        # Parse markdown line by line (ƒë∆°n gi·∫£n h∆°n)
        lines = markdown_text.split('\n')
        current_list = None
        
        for line in lines:
            line_stripped = line.strip()
            if not line_stripped:
                current_list = None
                continue
            
            # Headers
            if line_stripped.startswith('# '):
                doc.add_heading(line_stripped[2:], level=1)
                current_list = None
            elif line_stripped.startswith('## '):
                doc.add_heading(line_stripped[3:], level=2)
                current_list = None
            elif line_stripped.startswith('### '):
                doc.add_heading(line_stripped[4:], level=3)
                current_list = None
            elif line_stripped.startswith('#### '):
                doc.add_heading(line_stripped[5:], level=4)
                current_list = None
            # Images
            elif '![' in line_stripped:
                img_match = re.search(r'!\[([^\]]*)\]\(([^\)]+)\)', line_stripped)
                if img_match:
                    img_path = img_match.group(2)
                    if img_path.startswith('/outputs/'):
                        img_path = os.path.join(OUTPUT_FOLDER, img_path.replace('/outputs/', ''))
                    elif not os.path.isabs(img_path):
                        img_path = os.path.join(OUTPUT_FOLDER, img_path)
                    
                    if os.path.exists(img_path):
                        para = doc.add_paragraph()
                        run = para.add_run()
                        try:
                            run.add_picture(img_path, width=Inches(5))
                        except Exception as e:
                            print(f"Error adding image {img_path}: {e}")
                    else:
                        doc.add_paragraph(f"[Image: {img_match.group(1)}]")
                current_list = None
            # Lists
            elif line_stripped.startswith('- ') or line_stripped.startswith('* '):
                if current_list != 'ul':
                    current_list = 'ul'
                para = doc.add_paragraph(line_stripped[2:], style='List Bullet')
            elif re.match(r'^\d+\.\s', line_stripped):
                if current_list != 'ol':
                    current_list = 'ol'
                para = doc.add_paragraph(re.sub(r'^\d+\.\s', '', line_stripped), style='List Number')
            # Code blocks
            elif line_stripped.startswith('```'):
                continue
            # Regular text
            else:
                # Remove markdown formatting
                text = re.sub(r'\*\*(.*?)\*\*', r'\1', line_stripped)  # Bold
                text = re.sub(r'\*(.*?)\*', r'\1', text)  # Italic
                text = re.sub(r'`([^`]+)`', r'\1', text)  # Code
                para = doc.add_paragraph(text)
                current_list = None
        
        # Skip HTML parser, use simple markdown parsing instead
        from html.parser import HTMLParser
        
        class DocxHTMLParser(HTMLParser):
            def __init__(self, doc):
                super().__init__()
                self.doc = doc
                self.current_para = None
                self.current_run = None
                self.in_code = False
                self.in_pre = False
                
            def handle_starttag(self, tag, attrs):
                if tag == 'h1':
                    self.current_para = self.doc.add_heading('', level=1)
                elif tag == 'h2':
                    self.current_para = self.doc.add_heading('', level=2)
                elif tag == 'h3':
                    self.current_para = self.doc.add_heading('', level=3)
                elif tag == 'h4':
                    self.current_para = self.doc.add_heading('', level=4)
                elif tag == 'p':
                    self.current_para = self.doc.add_paragraph()
                elif tag == 'strong':
                    if self.current_para:
                        self.current_run = self.current_para.add_run()
                        self.current_run.bold = True
                elif tag == 'em':
                    if self.current_para:
                        self.current_run = self.current_para.add_run()
                        self.current_run.italic = True
                elif tag == 'code':
                    self.in_code = True
                elif tag == 'img':
                    # L·∫•y src t·ª´ attrs
                    src = dict(attrs).get('src', '')
                    if src:
                        try:
                            # Download image
                            if src.startswith('/'):
                                # Local file
                                img_path = os.path.join(OUTPUT_FOLDER, src.replace('/outputs/', ''))
                                if os.path.exists(img_path):
                                    self.current_para = self.doc.add_paragraph()
                                    run = self.current_para.add_run()
                                    run.add_picture(img_path, width=Inches(5))
                        except Exception as e:
                            print(f"Error adding image: {e}")
                elif tag == 'ul' or tag == 'ol':
                    self.current_para = self.doc.add_paragraph()
                elif tag == 'li':
                    if self.current_para:
                        self.current_para.style = 'List Bullet' if tag == 'ul' else 'List Number'
                
            def handle_endtag(self, tag):
                if tag in ['h1', 'h2', 'h3', 'h4', 'p']:
                    self.current_para = None
                    self.current_run = None
                elif tag == 'strong' or tag == 'em':
                    self.current_run = None
                elif tag == 'code':
                    self.in_code = False
                    
            def handle_data(self, data):
                if self.in_pre or self.in_code:
                    if self.current_para:
                        run = self.current_para.add_run(data)
                        run.font.name = 'Courier New'
                else:
                    if self.current_run:
                        self.current_run.add_text(data)
                    elif self.current_para:
                        self.current_para.add_run(data)
                    else:
                        self.current_para = self.doc.add_paragraph()
                        self.current_para.add_run(data)
        
        parser = DocxHTMLParser(doc)
        parser.feed(html)
        
        # Save to BytesIO
        output = BytesIO()
        doc.save(output)
        output.seek(0)
        
        return send_file(
            output,
            mimetype='application/vnd.openxmlformats-officedocument.wordprocessingml.document',
            as_attachment=True,
            download_name=filename
        )
        
    except ImportError:
        return jsonify({'error': 'python-docx ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t. Ch·∫°y: pip install python-docx markdown'}), 500
    except Exception as e:
        return jsonify({'error': f'L·ªói khi t·∫°o DOCX: {str(e)}'}), 500

@app.route('/api/ocr', methods=['POST'])
def ocr():
    """Process OCR request"""
    try:
        if model is None or tokenizer is None:
            return jsonify({
                'success': False,
                'error': 'Model ch∆∞a ƒë∆∞·ª£c t·∫£i. Vui l√≤ng ƒë·ª£i...'
            }), 503
        
        # Check if file is present
        if 'image' not in request.files:
            return jsonify({
                'success': False,
                'error': 'Kh√¥ng t√¨m th·∫•y file ·∫£nh'
            }), 400
        
        file = request.files['image']
        if file.filename == '':
            return jsonify({
                'success': False,
                'error': 'Ch∆∞a ch·ªçn file'
            }), 400
        
        if not allowed_file(file.filename):
            return jsonify({
                'success': False,
                'error': f'ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£. Ch·ªâ ch·∫•p nh·∫≠n: {", ".join(ALLOWED_EXTENSIONS)}'
            }), 400
        
        # Get prompt from form
        prompt_text = request.form.get('prompt', '').strip()
        output_format = request.form.get('format', 'markdown')  # markdown, text, full
        
        # Ch·ªçn prompt ph√π h·ª£p v·ªõi format - D√πng ƒë√∫ng prompt nh∆∞ DeepSeek-OCR c√¥ng b·ªë
        if not prompt_text:
            if output_format == 'markdown':
                # Prompt ch√≠nh x√°c nh∆∞ DeepSeek-OCR c√¥ng b·ªë
                prompt_text = '<image>\n<|grounding|>Convert the document to markdown.'
            elif output_format == 'full':
                prompt_text = '<image>\n<|grounding|>OCR this image.'
            else:
                prompt_text = '<image>\nFree OCR.'
        
        # Read image
        image_bytes = file.read()
        image = Image.open(io.BytesIO(image_bytes)).convert('RGB')
        
        # Save uploaded file
        filename = secure_filename(file.filename)
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        image.save(filepath)
        
        # Process OCR
        output_path = os.path.join(OUTPUT_FOLDER, f"result_{filename}")
        
        # Gi·∫£m k√≠ch th∆∞·ªõc ·∫£nh n·∫øu qu√° l·ªõn ƒë·ªÉ tr√°nh l·ªói CUDA
        actual_image_size = IMAGE_SIZE
        if image.size[0] > 2048 or image.size[1] > 2048:
            # Resize ·∫£nh l·ªõn xu·ªëng
            max_dim = max(image.size)
            if max_dim > 2048:
                scale = 2048 / max_dim
                new_size = (int(image.size[0] * scale), int(image.size[1] * scale))
                image = image.resize(new_size, Image.Resampling.LANCZOS)
                image.save(filepath)  # L∆∞u l·∫°i ·∫£nh ƒë√£ resize
                print(f"‚ö†Ô∏è  ·∫¢nh qu√° l·ªõn, ƒë√£ resize t·ª´ {image.size} xu·ªëng {new_size}")
        
        try:
            # Th·ª≠ v·ªõi image_size nh·ªè h∆°n n·∫øu g·∫∑p l·ªói
            result = model.infer(
                tokenizer,
                prompt=prompt_text,
                image_file=filepath,
                output_path=output_path,
                base_size=BASE_SIZE,
                image_size=min(actual_image_size, 640),  # Gi·ªõi h·∫°n t·ªëi ƒëa 640
                crop_mode=CROP_MODE,
                save_results=True,
                test_compress=False  # T·∫Øt test_compress ƒë·ªÉ tr√°nh l·ªói
            )
        except RuntimeError as e:
            error_str = str(e)
            if "masked_scatter" in error_str or "CUDA" in error_str:
                # Th·ª≠ l·∫°i v·ªõi image_size nh·ªè h∆°n
                print(f"‚ö†Ô∏è  L·ªói CUDA v·ªõi image_size={actual_image_size}, th·ª≠ l·∫°i v·ªõi 512...")
                try:
                    result = model.infer(
                        tokenizer,
                        prompt=prompt_text,
                        image_file=filepath,
                        output_path=output_path,
                        base_size=768,
                        image_size=512,
                        crop_mode=CROP_MODE,
                        save_results=True,
                        test_compress=False
                    )
                except Exception as e2:
                    raise Exception(f"L·ªói khi x·ª≠ l√Ω OCR (ƒë√£ th·ª≠ gi·∫£m k√≠ch th∆∞·ªõc): {str(e2)}")
            else:
                raise Exception(f"L·ªói khi x·ª≠ l√Ω OCR: {error_str}")
        except Exception as e:
            raise Exception(f"L·ªói khi x·ª≠ l√Ω OCR: {str(e)}")
        
        # Read result - try multiple methods
        result_text = ""
        
        # Method 1: Ki·ªÉm tra xem output_path l√† directory hay file
        possible_files = []
        
        # N·∫øu output_path l√† directory, t√¨m file .txt b√™n trong
        if os.path.isdir(output_path):
            print(f"üìÅ Output path l√† directory: {output_path}")
            # T√¨m file .mmd (markdown) tr∆∞·ªõc, sau ƒë√≥ .txt
            for f in os.listdir(output_path):
                if f.endswith('.mmd'):
                    possible_files.append(os.path.join(output_path, f))
            # N·∫øu kh√¥ng c√≥ .mmd, t√¨m .txt
            if not possible_files:
                for f in os.listdir(output_path):
                    if f.endswith('.txt'):
                        possible_files.append(os.path.join(output_path, f))
            # N·∫øu v·∫´n kh√¥ng c√≥, l·∫•y t·∫•t c·∫£ text files (kh√¥ng ph·∫£i image)
            if not possible_files:
                for f in os.listdir(output_path):
                    filepath_full = os.path.join(output_path, f)
                    if os.path.isfile(filepath_full) and not f.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp')):
                        possible_files.append(filepath_full)
        else:
            # N·∫øu l√† file, th·ª≠ c√°c extension
            possible_files = [
                f"{output_path}.mmd",
                f"{output_path}.txt",
                f"{output_path}",
            ]
        
        # Method 2: T√¨m file m·ªõi nh·∫•t trong OUTPUT_FOLDER c√≥ ch·ª©a filename
        output_dir = OUTPUT_FOLDER
        if os.path.exists(output_dir):
            all_files = []
            for item in os.listdir(output_dir):
                item_path = os.path.join(output_dir, item)
                # N·∫øu l√† directory c√≥ ch·ª©a filename
                if os.path.isdir(item_path) and filename in item:
                    # T√¨m file .mmd ho·∫∑c .txt trong directory n√†y
                    for f in os.listdir(item_path):
                        if f.endswith('.mmd') or f.endswith('.txt'):
                            filepath_full = os.path.join(item_path, f)
                            if os.path.isfile(filepath_full):
                                all_files.append((filepath_full, os.path.getmtime(filepath_full)))
                # N·∫øu l√† file c√≥ ch·ª©a filename
                elif os.path.isfile(item_path) and (filename in item or "result_" in item):
                    all_files.append((item_path, os.path.getmtime(item_path)))
            
            if all_files:
                # S·∫Øp x·∫øp theo th·ªùi gian, l·∫•y file m·ªõi nh·∫•t
                all_files.sort(key=lambda x: x[1], reverse=True)
                possible_files.insert(0, all_files[0][0])
        
        # Method 3: Th√™m c√°c path kh√°c
        possible_files.extend([
            os.path.join(output_dir, f"result_{filename}.txt"),
            os.path.join(output_dir, f"result_{filename}"),
        ])
        
        # Th·ª≠ ƒë·ªçc t·ª´ c√°c file c√≥ th·ªÉ
        for file_path in possible_files:
            if os.path.exists(file_path) and os.path.isfile(file_path):
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read().strip()
                        if content and len(content) > 10:  # ƒê·∫£m b·∫£o c√≥ n·ªôi dung
                            result_text = content
                            print(f"‚úÖ ƒê√£ ƒë·ªçc k·∫øt qu·∫£ t·ª´: {file_path}")
                            break
                except Exception as e:
                    print(f"‚ö†Ô∏è  Kh√¥ng th·ªÉ ƒë·ªçc file {file_path}: {e}")
                    continue
        
        # Method 2: Try to get from result object
        if not result_text and result is not None:
            if isinstance(result, dict):
                result_text = result.get('text', result.get('result', result.get('output', str(result))))
            elif isinstance(result, str):
                result_text = result
            elif hasattr(result, 'text'):
                result_text = result.text
            elif hasattr(result, 'output'):
                result_text = result.output
            else:
                result_text = str(result) if result else ""
        
        # Method 4: N·∫øu v·∫´n kh√¥ng c√≥, t√¨m trong OUTPUT_FOLDER file/directory m·ªõi nh·∫•t
        if not result_text and os.path.exists(OUTPUT_FOLDER):
            try:
                all_items = []
                for item in os.listdir(OUTPUT_FOLDER):
                    item_path = os.path.join(OUTPUT_FOLDER, item)
                    if os.path.isfile(item_path):
                        all_items.append((item_path, os.path.getmtime(item_path), 'file'))
                    elif os.path.isdir(item_path):
                        # T√¨m file .txt trong directory
                        for f in os.listdir(item_path):
                            if f.endswith('.mmd') or f.endswith('.txt'):
                                filepath_full = os.path.join(item_path, f)
                                if os.path.isfile(filepath_full):
                                    all_items.append((filepath_full, os.path.getmtime(filepath_full), 'file'))
                                    break
                
                if all_items:
                    # L·∫•y file m·ªõi nh·∫•t
                    latest_item = max(all_items, key=lambda x: x[1])
                    latest_path = latest_item[0]
                    with open(latest_path, 'r', encoding='utf-8') as f:
                        content = f.read().strip()
                        if content:
                            result_text = content
                            print(f"‚úÖ ƒê√£ ƒë·ªçc k·∫øt qu·∫£ t·ª´ file m·ªõi nh·∫•t: {os.path.basename(latest_path)}")
            except Exception as e:
                print(f"‚ö†Ô∏è  Kh√¥ng th·ªÉ ƒë·ªçc file m·ªõi nh·∫•t: {e}")
        
        # Clean up v√† format result text - Gi·ªØ nguy√™n output t·ª´ DeepSeek-OCR
        if result_text:
            # Ch·ªâ strip ƒë·∫ßu cu·ªëi, gi·ªØ nguy√™n m·ªçi th·ª© b√™n trong
            result_text = result_text.strip()
            
            # S·ª≠a image paths trong markdown ƒë·ªÉ tr·ªè ƒë√∫ng output directory
            if output_format == 'markdown' and os.path.isdir(output_path):
                # T√¨m t√™n directory ƒë·ªÉ build path
                output_dir_name = os.path.basename(output_path)
                # S·ª≠a image paths: images/0.jpg -> /outputs/{output_dir_name}/0.jpg
                result_text = re.sub(
                    r'!\[([^\]]*)\]\(images/([^\)]+)\)',
                    lambda m: f'![{m.group(1)}](/outputs/{output_dir_name}/{m.group(2)})',
                    result_text
                )
                # S·ª≠a relative paths kh√°c
                result_text = re.sub(
                    r'!\[([^\]]*)\]\(([^/\)]+\.(jpg|jpeg|png|gif|bmp|webp))\)',
                    lambda m: f'![{m.group(1)}](/outputs/{output_dir_name}/{m.group(2)})',
                    result_text
                )
            
            # Format ch·ªâ khi c·∫ßn (c√≥ tags ho·∫∑c format kh√°c markdown)
            # N·∫øu ƒë√£ l√† markdown s·∫°ch, gi·ªØ nguy√™n 100%
            formatted_text = format_ocr_result(result_text, output_format)
        else:
            formatted_text = "Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£. Vui l√≤ng ki·ªÉm tra logs."
            print(f"‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£. Output path: {output_path}")
            print(f"‚ö†Ô∏è  Files trong OUTPUT_FOLDER: {os.listdir(OUTPUT_FOLDER) if os.path.exists(OUTPUT_FOLDER) else 'Kh√¥ng t·ªìn t·∫°i'}")
        
        return jsonify({
            'success': True,
            'text': formatted_text,
            'raw_text': result_text if result_text else "",
            'filename': filename,
            'format': output_format
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'L·ªói x·ª≠ l√Ω: {str(e)}'
        }), 500

@app.route('/api/ocr-base64', methods=['POST'])
def ocr_base64():
    """Process OCR from base64 image"""
    try:
        if model is None or tokenizer is None:
            return jsonify({
                'success': False,
                'error': 'Model ch∆∞a ƒë∆∞·ª£c t·∫£i. Vui l√≤ng ƒë·ª£i...'
            }), 503
        
        data = request.get_json()
        if not data or 'image' not in data:
            return jsonify({
                'success': False,
                'error': 'Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ·∫£nh'
            }), 400
        
        # Decode base64 image
        image_data = data['image']
        if image_data.startswith('data:image'):
            image_data = image_data.split(',')[1]
        
        image_bytes = base64.b64decode(image_data)
        image = Image.open(io.BytesIO(image_bytes)).convert('RGB')
        
        # Get prompt
        prompt_text = data.get('prompt', '<image>\nFree OCR.')
        if not prompt_text.strip():
            prompt_text = '<image>\nFree OCR.'
        
        # Save temporary file
        import uuid
        temp_filename = f"temp_{uuid.uuid4().hex}.png"
        temp_filepath = os.path.join(app.config['UPLOAD_FOLDER'], temp_filename)
        image.save(temp_filepath)
        
        # Process OCR
        output_path = os.path.join(OUTPUT_FOLDER, f"result_{temp_filename}")
        
        # Gi·∫£m k√≠ch th∆∞·ªõc ·∫£nh n·∫øu qu√° l·ªõn
        if image.size[0] > 2048 or image.size[1] > 2048:
            max_dim = max(image.size)
            if max_dim > 2048:
                scale = 2048 / max_dim
                new_size = (int(image.size[0] * scale), int(image.size[1] * scale))
                image = image.resize(new_size, Image.Resampling.LANCZOS)
                image.save(temp_filepath)
                print(f"‚ö†Ô∏è  ·∫¢nh qu√° l·ªõn, ƒë√£ resize t·ª´ {image.size} xu·ªëng {new_size}")
        
        try:
            result = model.infer(
                tokenizer,
                prompt=prompt_text,
                image_file=temp_filepath,
                output_path=output_path,
                base_size=BASE_SIZE,
                image_size=min(IMAGE_SIZE, 640),  # Gi·ªõi h·∫°n t·ªëi ƒëa 640
                crop_mode=CROP_MODE,
                save_results=True,
                test_compress=False  # T·∫Øt test_compress ƒë·ªÉ tr√°nh l·ªói
            )
        except RuntimeError as e:
            error_str = str(e)
            if "masked_scatter" in error_str or "CUDA" in error_str:
                print(f"‚ö†Ô∏è  L·ªói CUDA, th·ª≠ l·∫°i v·ªõi image_size nh·ªè h∆°n...")
                try:
                    result = model.infer(
                        tokenizer,
                        prompt=prompt_text,
                        image_file=temp_filepath,
                        output_path=output_path,
                        base_size=768,
                        image_size=512,
                        crop_mode=CROP_MODE,
                        save_results=True,
                        test_compress=False
                    )
                except Exception as e2:
                    raise Exception(f"L·ªói khi x·ª≠ l√Ω OCR (ƒë√£ th·ª≠ gi·∫£m k√≠ch th∆∞·ªõc): {str(e2)}")
            else:
                raise Exception(f"L·ªói khi x·ª≠ l√Ω OCR: {error_str}")
        except Exception as e:
            raise Exception(f"L·ªói khi x·ª≠ l√Ω OCR: {str(e)}")
        
        # Read result - try multiple methods (same as ocr function)
        result_text = ""
        
        # Method 1: Ki·ªÉm tra xem output_path l√† directory hay file
        possible_files = []
        
        # N·∫øu output_path l√† directory, t√¨m file .txt b√™n trong
        if os.path.isdir(output_path):
            print(f"üìÅ Output path l√† directory: {output_path}")
            # T√¨m file .mmd (markdown) tr∆∞·ªõc, sau ƒë√≥ .txt
            for f in os.listdir(output_path):
                if f.endswith('.mmd'):
                    possible_files.append(os.path.join(output_path, f))
            # N·∫øu kh√¥ng c√≥ .mmd, t√¨m .txt
            if not possible_files:
                for f in os.listdir(output_path):
                    if f.endswith('.txt'):
                        possible_files.append(os.path.join(output_path, f))
            # N·∫øu v·∫´n kh√¥ng c√≥, l·∫•y t·∫•t c·∫£ text files (kh√¥ng ph·∫£i image)
            if not possible_files:
                for f in os.listdir(output_path):
                    filepath_full = os.path.join(output_path, f)
                    if os.path.isfile(filepath_full) and not f.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp')):
                        possible_files.append(filepath_full)
        else:
            # N·∫øu l√† file, th·ª≠ c√°c extension
            possible_files = [
                f"{output_path}.mmd",
                f"{output_path}.txt",
                f"{output_path}",
            ]
        
        # Method 2: T√¨m file m·ªõi nh·∫•t trong OUTPUT_FOLDER c√≥ ch·ª©a temp_filename
        if os.path.exists(OUTPUT_FOLDER):
            all_files = []
            for item in os.listdir(OUTPUT_FOLDER):
                item_path = os.path.join(OUTPUT_FOLDER, item)
                # N·∫øu l√† directory c√≥ ch·ª©a temp_filename
                if os.path.isdir(item_path) and temp_filename in item:
                    # T√¨m file .mmd ho·∫∑c .txt trong directory n√†y
                    for f in os.listdir(item_path):
                        if f.endswith('.mmd') or f.endswith('.txt'):
                            filepath_full = os.path.join(item_path, f)
                            if os.path.isfile(filepath_full):
                                all_files.append((filepath_full, os.path.getmtime(filepath_full)))
                # N·∫øu l√† file c√≥ ch·ª©a temp_filename
                elif os.path.isfile(item_path) and (temp_filename in item or "result_" in item):
                    all_files.append((item_path, os.path.getmtime(item_path)))
            
            if all_files:
                all_files.sort(key=lambda x: x[1], reverse=True)
                possible_files.insert(0, all_files[0][0])
        
        # Method 3: Th√™m c√°c path kh√°c
        possible_files.extend([
            os.path.join(OUTPUT_FOLDER, f"result_{temp_filename}.txt"),
            os.path.join(OUTPUT_FOLDER, f"result_{temp_filename}"),
        ])
        
        for file_path in possible_files:
            if os.path.exists(file_path) and os.path.isfile(file_path):
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read().strip()
                        if content and len(content) > 10:
                            result_text = content
                            print(f"‚úÖ ƒê√£ ƒë·ªçc k·∫øt qu·∫£ t·ª´: {file_path}")
                            break
                except Exception as e:
                    print(f"‚ö†Ô∏è  Kh√¥ng th·ªÉ ƒë·ªçc file {file_path}: {e}")
                    continue
        
        # Method 2: Try result object
        if not result_text and result is not None:
            if isinstance(result, dict):
                result_text = result.get('text', result.get('result', result.get('output', str(result))))
            elif isinstance(result, str):
                result_text = result
            elif hasattr(result, 'text'):
                result_text = result.text
            elif hasattr(result, 'output'):
                result_text = result.output
            else:
                result_text = str(result) if result else ""
        
        # Method 3: T√¨m file m·ªõi nh·∫•t trong OUTPUT_FOLDER
        if not result_text and os.path.exists(OUTPUT_FOLDER):
            try:
                all_items = []
                for item in os.listdir(OUTPUT_FOLDER):
                    item_path = os.path.join(OUTPUT_FOLDER, item)
                    if os.path.isfile(item_path):
                        all_items.append((item_path, os.path.getmtime(item_path), 'file'))
                    elif os.path.isdir(item_path):
                        # T√¨m file .txt trong directory
                        for f in os.listdir(item_path):
                            if f.endswith('.mmd') or f.endswith('.txt'):
                                filepath_full = os.path.join(item_path, f)
                                if os.path.isfile(filepath_full):
                                    all_items.append((filepath_full, os.path.getmtime(filepath_full), 'file'))
                                    break
                
                if all_items:
                    latest_item = max(all_items, key=lambda x: x[1])
                    latest_path = latest_item[0]
                    with open(latest_path, 'r', encoding='utf-8') as f:
                        content = f.read().strip()
                        if content:
                            result_text = content
                            print(f"‚úÖ ƒê√£ ƒë·ªçc k·∫øt qu·∫£ t·ª´ file m·ªõi nh·∫•t: {os.path.basename(latest_path)}")
            except Exception as e:
                print(f"‚ö†Ô∏è  Kh√¥ng th·ªÉ ƒë·ªçc file m·ªõi nh·∫•t: {e}")
        
        if result_text:
            result_text = result_text.strip()
        
        # Clean up temp file
        try:
            os.remove(temp_filepath)
        except:
            pass
        
        return jsonify({
            'success': True,
            'text': result_text if result_text else "Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£. Vui l√≤ng ki·ªÉm tra logs."
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'L·ªói x·ª≠ l√Ω: {str(e)}'
        }), 500

if __name__ == '__main__':
    print("=" * 50)
    print("ƒêang kh·ªüi t·∫°o DeepSeek-OCR Web Application...")
    print("=" * 50)
    
    # Initialize model
    if init_model():
        print(f"\nServer ƒëang ch·∫°y t·∫°i: http://{HOST}:{PORT}")
        print("Nh·∫•n Ctrl+C ƒë·ªÉ d·ª´ng server\n")
        app.run(host=HOST, port=PORT, debug=DEBUG)
    else:
        print("Kh√¥ng th·ªÉ kh·ªüi t·∫°o model. Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u h√¨nh.")

