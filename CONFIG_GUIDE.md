# üìã H∆∞·ªõng d·∫´n c·∫•u h√¨nh h·ªá th·ªëng

## üéØ C√°c m·ª©c c·∫•u h√¨nh ƒë∆∞·ª£c h·ªó tr·ª£

### ‚≠ê C·∫•u h√¨nh T·ªëi thi·ªÉu (CPU Only)

**Ph·∫ßn c·ª©ng:**
- **CPU**: Intel i5 th·∫ø h·ªá 8+ ho·∫∑c AMD Ryzen 5 3000+ (4 cores tr·ªü l√™n)
- **RAM**: 8GB (t·ªëi thi·ªÉu) - 16GB (khuy·∫øn ngh·ªã)
- **·ªî c·ª©ng**: 50GB tr·ªëng (ƒë·ªÉ t·∫£i model ~20-30GB)
- **GPU**: Kh√¥ng c·∫ßn

**C·∫•u h√¨nh trong `config.py`:**
```python
DEVICE = 'cpu'
DTYPE = 'float32'  # ho·∫∑c 'float16'
IMAGE_SIZE = 512   # Gi·∫£m k√≠ch th∆∞·ªõc ƒë·ªÉ ti·∫øt ki·ªám RAM
BASE_SIZE = 768
```

**Hi·ªáu su·∫•t:**
- ‚è±Ô∏è Th·ªùi gian x·ª≠ l√Ω: 30-60 gi√¢y/·∫£nh
- üíæ RAM s·ª≠ d·ª•ng: ~6-8GB
- ‚úÖ **C√≥ th·ªÉ ch·∫°y ƒë∆∞·ª£c** nh∆∞ng ch·∫≠m

---

### üöÄ C·∫•u h√¨nh Khuy·∫øn ngh·ªã (GPU Entry-level)

**Ph·∫ßn c·ª©ng:**
- **GPU**: NVIDIA GTX 1660, RTX 2060, RTX 3050 (6GB VRAM)
- **CPU**: Intel i5/i7 ho·∫∑c AMD Ryzen 5/7
- **RAM**: 16GB
- **·ªî c·ª©ng**: 50GB tr·ªëng
- **CUDA**: 11.8+

**C·∫•u h√¨nh trong `config.py`:**
```python
DEVICE = 'cuda'
DTYPE = 'bfloat16'  # ho·∫∑c 'float16'
IMAGE_SIZE = 640
BASE_SIZE = 1024
```

**Hi·ªáu su·∫•t:**
- ‚è±Ô∏è Th·ªùi gian x·ª≠ l√Ω: 5-15 gi√¢y/·∫£nh
- üíæ VRAM s·ª≠ d·ª•ng: ~4-6GB
- ‚úÖ **Ch·∫°y t·ªët** cho h·∫ßu h·∫øt tr∆∞·ªùng h·ª£p

---

### ‚ö° C·∫•u h√¨nh T·ªëi ∆∞u (GPU Mid-range)

**Ph·∫ßn c·ª©ng:**
- **GPU**: NVIDIA RTX 3060, RTX 3070, RTX 4060 (8-12GB VRAM)
- **CPU**: Intel i7/i9 ho·∫∑c AMD Ryzen 7/9
- **RAM**: 16-32GB
- **·ªî c·ª©ng**: 100GB tr·ªëng
- **CUDA**: 11.8+

**C·∫•u h√¨nh trong `config.py`:**
```python
DEVICE = 'cuda'
DTYPE = 'bfloat16'
IMAGE_SIZE = 640
BASE_SIZE = 1024
```

**Hi·ªáu su·∫•t:**
- ‚è±Ô∏è Th·ªùi gian x·ª≠ l√Ω: 3-8 gi√¢y/·∫£nh
- üíæ VRAM s·ª≠ d·ª•ng: ~6-8GB
- ‚úÖ **Ch·∫°y r·∫•t t·ªët**, x·ª≠ l√Ω nhanh

---

### üî• C·∫•u h√¨nh Cao c·∫•p (GPU High-end)

**Ph·∫ßn c·ª©ng:**
- **GPU**: NVIDIA RTX 3080, RTX 3090, RTX 4080, RTX 4090, A100 (10GB+ VRAM)
- **CPU**: Intel i9 ho·∫∑c AMD Ryzen 9
- **RAM**: 32GB+
- **·ªî c·ª©ng**: 100GB+ tr·ªëng
- **CUDA**: 11.8+

**C·∫•u h√¨nh trong `config.py`:**
```python
DEVICE = 'cuda'
DTYPE = 'bfloat16'
IMAGE_SIZE = 1280  # C√≥ th·ªÉ tƒÉng l√™n
BASE_SIZE = 1024
```

**Hi·ªáu su·∫•t:**
- ‚è±Ô∏è Th·ªùi gian x·ª≠ l√Ω: 1-3 gi√¢y/·∫£nh
- üíæ VRAM s·ª≠ d·ª•ng: ~8-12GB
- ‚úÖ **Ch·∫°y c·ª±c nhanh**, x·ª≠ l√Ω ·∫£nh l·ªõn

---

## üîß C√°ch ki·ªÉm tra c·∫•u h√¨nh h·ªá th·ªëng

### Ki·ªÉm tra GPU (Windows)
```powershell
nvidia-smi
```

### Ki·ªÉm tra RAM (Windows)
```powershell
systeminfo | findstr "Total Physical Memory"
```

### Ki·ªÉm tra Python v√† PyTorch
```bash
python --version
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}'); print(f'CUDA version: {torch.version.cuda if torch.cuda.is_available() else \"N/A\"}')"
```

---

## ‚öôÔ∏è T·ªëi ∆∞u h√≥a theo c·∫•u h√¨nh

### N·∫øu g·∫∑p l·ªói "Out of Memory":

1. **Gi·∫£m IMAGE_SIZE:**
   ```python
   IMAGE_SIZE = 512  # Thay v√¨ 640
   BASE_SIZE = 768   # Thay v√¨ 1024
   ```

2. **Chuy·ªÉn sang CPU:**
   ```python
   DEVICE = 'cpu'
   DTYPE = 'float32'
   ```

3. **Gi·∫£m batch size** (n·∫øu x·ª≠ l√Ω nhi·ªÅu ·∫£nh):
   - X·ª≠ l√Ω t·ª´ng ·∫£nh m·ªôt

### N·∫øu ch·∫°y qu√° ch·∫≠m:

1. **ƒê·∫£m b·∫£o c√≥ GPU:**
   ```python
   DEVICE = 'cuda'
   ```

2. **S·ª≠ d·ª•ng dtype nh·∫π h∆°n:**
   ```python
   DTYPE = 'bfloat16'  # ho·∫∑c 'float16'
   ```

3. **C√†i flash-attn** (n·∫øu c√≥ GPU):
   ```bash
   pip install flash-attn==2.7.3 --no-build-isolation
   ```

---

## üìä B·∫£ng so s√°nh c·∫•u h√¨nh

| C·∫•u h√¨nh | GPU VRAM | RAM | Th·ªùi gian/·∫£nh | Khuy·∫øn ngh·ªã |
|----------|----------|-----|---------------|-------------|
| T·ªëi thi·ªÉu | 0GB (CPU) | 8GB | 30-60s | ‚ö†Ô∏è Ch·∫≠m, ch·ªâ d√πng khi kh√¥ng c√≥ GPU |
| Entry | 6GB | 16GB | 5-15s | ‚úÖ T·ªët cho h·∫ßu h·∫øt ng∆∞·ªùi d√πng |
| Mid-range | 8-12GB | 16-32GB | 3-8s | ‚≠ê Khuy·∫øn ngh·ªã |
| High-end | 10GB+ | 32GB+ | 1-3s | üî• T·ªëi ∆∞u nh·∫•t |

---

## üéØ Khuy·∫øn ngh·ªã cho b·∫°n

**N·∫øu b·∫°n c√≥:**
- **Laptop/PC th√¥ng th∆∞·ªùng** (kh√¥ng c√≥ GPU NVIDIA) ‚Üí D√πng c·∫•u h√¨nh CPU, ch·∫•p nh·∫≠n ch·∫≠m
- **GPU NVIDIA 6GB** (GTX 1660, RTX 2060) ‚Üí C·∫•u h√¨nh Entry-level, ch·∫°y t·ªët
- **GPU NVIDIA 8GB+** (RTX 3060, RTX 3070) ‚Üí C·∫•u h√¨nh Mid-range, ch·∫°y r·∫•t t·ªët
- **GPU NVIDIA 10GB+** (RTX 3080, RTX 4090) ‚Üí C·∫•u h√¨nh High-end, ch·∫°y c·ª±c nhanh

---

## üí° Tips t·ªëi ∆∞u

1. **Lu√¥n ki·ªÉm tra VRAM tr∆∞·ªõc:**
   ```bash
   nvidia-smi
   ```

2. **B·∫Øt ƒë·∫ßu v·ªõi c·∫•u h√¨nh th·∫•p**, sau ƒë√≥ tƒÉng d·∫ßn n·∫øu kh√¥ng l·ªói

3. **X·ª≠ l√Ω ·∫£nh nh·ªè h∆°n** n·∫øu g·∫∑p l·ªói memory

4. **ƒê√≥ng c√°c ·ª©ng d·ª•ng kh√°c** khi ch·∫°y ƒë·ªÉ gi·∫£i ph√≥ng RAM/VRAM

5. **S·ª≠ d·ª•ng CPU n·∫øu GPU kh√¥ng ƒë·ªß VRAM** - ch·∫≠m nh∆∞ng v·∫´n ch·∫°y ƒë∆∞·ª£c

---

## ‚ùì C√¢u h·ªèi th∆∞·ªùng g·∫∑p

**Q: T√¥i ch·ªâ c√≥ 4GB RAM, ch·∫°y ƒë∆∞·ª£c kh√¥ng?**
A: R·∫•t kh√≥. Khuy·∫øn ngh·ªã t·ªëi thi·ªÉu 8GB RAM.

**Q: GPU AMD c√≥ ch·∫°y ƒë∆∞·ª£c kh√¥ng?**
A: Hi·ªán t·∫°i ch·ªâ h·ªó tr·ª£ NVIDIA CUDA. GPU AMD s·∫Ω ch·∫°y tr√™n CPU (ch·∫≠m).

**Q: MacBook M1/M2 ch·∫°y ƒë∆∞·ª£c kh√¥ng?**
A: C√≥ th·ªÉ ch·∫°y tr√™n CPU, nh∆∞ng c·∫ßn c√†i PyTorch cho Mac (kh√¥ng d√πng CUDA).

**Q: Model n·∫∑ng bao nhi√™u?**
A: Kho·∫£ng 20-30GB khi t·∫£i v·ªÅ t·ª´ Hugging Face.

**Q: C√≥ th·ªÉ ch·∫°y tr√™n Google Colab kh√¥ng?**
A: C√≥! Colab c√≥ GPU mi·ªÖn ph√≠ (T4) ƒë·ªß ƒë·ªÉ ch·∫°y.

