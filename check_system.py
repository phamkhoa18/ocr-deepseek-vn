"""
Script ki·ªÉm tra c·∫•u h√¨nh h·ªá th·ªëng v√† ƒë∆∞a ra khuy·∫øn ngh·ªã
"""
import sys
import platform

def check_system():
    print("=" * 60)
    print("KI·ªÇM TRA C·∫§U H√åNH H·ªÜ TH·ªêNG")
    print("=" * 60)
    
    # Python version
    print(f"\nüêç Python: {sys.version.split()[0]}")
    
    # OS
    print(f"üíª H·ªá ƒëi·ªÅu h√†nh: {platform.system()} {platform.release()}")
    
    # Check PyTorch
    try:
        import torch
        print(f"üî• PyTorch: {torch.__version__}")
        
        # Check CUDA
        if torch.cuda.is_available():
            print(f"‚úÖ CUDA: C√≥ s·∫µn")
            print(f"   - CUDA Version: {torch.version.cuda}")
            print(f"   - GPU: {torch.cuda.get_device_name(0)}")
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
            print(f"   - VRAM: {gpu_memory:.1f}GB")
            
            # ƒê√°nh gi√° GPU
            if gpu_memory >= 10:
                print("   ‚≠ê ƒê√°nh gi√°: GPU Cao c·∫•p - Ch·∫°y r·∫•t t·ªët!")
            elif gpu_memory >= 8:
                print("   ‚≠ê ƒê√°nh gi√°: GPU T·ªët - Ch·∫°y t·ªët!")
            elif gpu_memory >= 6:
                print("   ‚≠ê ƒê√°nh gi√°: GPU Entry-level - Ch·∫°y ƒë∆∞·ª£c!")
            else:
                print("   ‚ö†Ô∏è ƒê√°nh gi√°: GPU VRAM th·∫•p - C√≥ th·ªÉ g·∫∑p l·ªói OOM")
        else:
            print("‚ùå CUDA: Kh√¥ng c√≥ (s·∫Ω ch·∫°y tr√™n CPU - ch·∫≠m h∆°n)")
    except ImportError:
        print("‚ùå PyTorch: Ch∆∞a c√†i ƒë·∫∑t")
        print("   Ch·∫°y: pip install torch torchvision torchaudio")
    
    # Check RAM (Windows)
    try:
        if platform.system() == 'Windows':
            import psutil
            ram_total = psutil.virtual_memory().total / (1024**3)
            ram_available = psutil.virtual_memory().available / (1024**3)
            print(f"\nüíæ RAM:")
            print(f"   - T·ªïng: {ram_total:.1f}GB")
            print(f"   - C√≤n tr·ªëng: {ram_available:.1f}GB")
            
            if ram_total >= 32:
                print("   ‚≠ê ƒê√°nh gi√°: RAM D·ªìi d√†o - T·ªët!")
            elif ram_total >= 16:
                print("   ‚≠ê ƒê√°nh gi√°: RAM ƒê·ªß - T·ªët!")
            elif ram_total >= 8:
                print("   ‚ö†Ô∏è ƒê√°nh gi√°: RAM T·ªëi thi·ªÉu - C√≥ th·ªÉ ch·∫≠m")
            else:
                print("   ‚ùå ƒê√°nh gi√°: RAM Qu√° th·∫•p - Kh√¥ng khuy·∫øn ngh·ªã")
    except ImportError:
        print("\nüíæ RAM: Kh√¥ng th·ªÉ ki·ªÉm tra (c√†i psutil ƒë·ªÉ ki·ªÉm tra)")
        print("   Ch·∫°y: pip install psutil")
    except Exception as e:
        print(f"\nüíæ RAM: L·ªói khi ki·ªÉm tra: {e}")
    
    # Check disk space
    try:
        import shutil
        disk_total, disk_used, disk_free = shutil.disk_usage('.')
        disk_free_gb = disk_free / (1024**3)
        print(f"\nüíø ·ªî c·ª©ng:")
        print(f"   - C√≤n tr·ªëng: {disk_free_gb:.1f}GB")
        
        if disk_free_gb >= 100:
            print("   ‚≠ê ƒê√°nh gi√°: ƒê·ªß dung l∆∞·ª£ng!")
        elif disk_free_gb >= 50:
            print("   ‚ö†Ô∏è ƒê√°nh gi√°: ƒê·ªß nh∆∞ng h∆°i √≠t (model ~30GB)")
        else:
            print("   ‚ùå ƒê√°nh gi√°: Thi·∫øu dung l∆∞·ª£ng - C·∫ßn √≠t nh·∫•t 50GB")
    except Exception as e:
        print(f"\nüíø ·ªî c·ª©ng: L·ªói khi ki·ªÉm tra: {e}")
    
    # Khuy·∫øn ngh·ªã
    print("\n" + "=" * 60)
    print("KHUY·∫æN NGH·ªä C·∫§U H√åNH")
    print("=" * 60)
    
    try:
        import torch
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
            if gpu_memory >= 10:
                print("\n‚úÖ C·∫•u h√¨nh ƒë·ªÅ xu·∫•t trong config.py:")
                print("   DEVICE = 'cuda'")
                print("   DTYPE = 'bfloat16'")
                print("   IMAGE_SIZE = 1280")
                print("   BASE_SIZE = 1024")
            elif gpu_memory >= 8:
                print("\n‚úÖ C·∫•u h√¨nh ƒë·ªÅ xu·∫•t trong config.py:")
                print("   DEVICE = 'cuda'")
                print("   DTYPE = 'bfloat16'")
                print("   IMAGE_SIZE = 640")
                print("   BASE_SIZE = 1024")
            elif gpu_memory >= 6:
                print("\n‚úÖ C·∫•u h√¨nh ƒë·ªÅ xu·∫•t trong config.py:")
                print("   DEVICE = 'cuda'")
                print("   DTYPE = 'bfloat16'")
                print("   IMAGE_SIZE = 640")
                print("   BASE_SIZE = 1024")
            else:
                print("\n‚ö†Ô∏è C·∫•u h√¨nh ƒë·ªÅ xu·∫•t trong config.py:")
                print("   DEVICE = 'cuda'")
                print("   DTYPE = 'float16'")
                print("   IMAGE_SIZE = 512")
                print("   BASE_SIZE = 768")
        else:
            print("\n‚ö†Ô∏è C·∫•u h√¨nh ƒë·ªÅ xu·∫•t trong config.py (CPU):")
            print("   DEVICE = 'cpu'")
            print("   DTYPE = 'float32'")
            print("   IMAGE_SIZE = 512")
            print("   BASE_SIZE = 768")
            print("\nüí° L∆∞u √Ω: Ch·∫°y tr√™n CPU s·∫Ω r·∫•t ch·∫≠m (30-60s/·∫£nh)")
    except:
        print("\n‚ö†Ô∏è Kh√¥ng th·ªÉ ƒë∆∞a ra khuy·∫øn ngh·ªã (ch∆∞a c√†i PyTorch)")
    
    print("\n" + "=" * 60)
    print("ƒê·ªÉ ch·∫°y ·ª©ng d·ª•ng: python app.py")
    print("=" * 60)

if __name__ == '__main__':
    check_system()

